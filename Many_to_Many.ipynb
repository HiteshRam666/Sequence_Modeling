{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0y-As0pMmXF",
        "outputId": "cc68d1b7-3b81-4ea3-b90e-6bcf4d994e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import re\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(stopwords.words(\"english\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_data = \"/content/harry_potter\""
      ],
      "metadata": {
        "id": "fjEqLE_NRUbx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_files = os.listdir(path_to_data)"
      ],
      "metadata": {
        "id": "15Hdp7OJUveE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_text = \" \"\n",
        "\n",
        "for text in text_files:\n",
        "  path_to_book = os.path.join(path_to_data, text)\n",
        "\n",
        "  with open(path_to_book, 'r') as f:\n",
        "    text = f.readlines()\n",
        "\n",
        "  text = [line for line in text if \"Page\" not in line]\n",
        "  text = \" \".join(text).replace(\"\\n\", \"\")\n",
        "  text = [word for word in text.split(\" \") if len(word) > 0]\n",
        "  text = \" \".join(text)\n",
        "  all_text = text"
      ],
      "metadata": {
        "id": "TCpbvArRZAc6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_chars = sorted(list(set(all_text)))"
      ],
      "metadata": {
        "id": "hLzUjqV12of6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(unique_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFR1lozD2vMF",
        "outputId": "824a3d6e-2db4-40ee-9adc-8ebb47fcfc95"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '9', ':', ';', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '\\\\', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—', '‘', '’', '“', '”', '•']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(unique_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Kb-akEz2wNv",
        "outputId": "5a58f685-3d75-442f-aa2b-1a9a2c8df70f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx = {c:i for (i, c) in enumerate(unique_chars)}"
      ],
      "metadata": {
        "id": "5eF_WAnD2zxa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {i:c for (i, c) in enumerate(unique_chars)}"
      ],
      "metadata": {
        "id": "GtqKW2Ig3Lmi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8Kzzxqu5WtR",
        "outputId": "f9f3a35d-87f6-434e-cd4a-adf6c9cdbb5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1121342"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataBuilder:\n",
        "  def __init__(self, seq_len = 200, text = all_text):\n",
        "    self.seq_len = seq_len\n",
        "    self.text = text\n",
        "    self.file_length = len(text)\n",
        "\n",
        "  def grab_random_sample(self):\n",
        "\n",
        "    start = np.random.randint(0, self.file_length - self.seq_len)\n",
        "    end = start + self.seq_len\n",
        "\n",
        "    text_slice = self.text[start:end]\n",
        "\n",
        "    input_text = text_slice[:-1]\n",
        "    label = text_slice[1:]\n",
        "\n",
        "    input_text = torch.tensor([char2idx[c] for c in input_text])\n",
        "    label = torch.tensor([char2idx[c] for c in label])\n",
        "\n",
        "    return input_text, label\n",
        "\n",
        "  def grab_random_batch(self, batch_size):\n",
        "    input_texts, labels = [], []\n",
        "\n",
        "    for _ in range(batch_size):\n",
        "      input_text, label = self.grab_random_sample()\n",
        "\n",
        "      input_texts.append(input_text)\n",
        "      labels.append(label)\n",
        "\n",
        "    input_texts = torch.stack(input_texts)\n",
        "    labels = torch.stack(labels)\n",
        "\n",
        "    return input_texts, labels"
      ],
      "metadata": {
        "id": "n06leckT3THM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DataBuilder(seq_len = 10)\n",
        "input_texts, labels = dataset.grab_random_batch(batch_size=4)"
      ],
      "metadata": {
        "id": "CVGj_V0_6vpc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model**"
      ],
      "metadata": {
        "id": "dKh2G2Hs7lCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMGenerator(nn.Module):\n",
        "  def __init__(self, embedding_dim = 120, num_characters = len(char2idx), hidden_size = 256, num_layers = 3, device = \"cpu\"):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.num_characters = num_characters\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.device = device\n",
        "\n",
        "    self.embedding = nn.Embedding(num_characters, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first = True)\n",
        "\n",
        "    self.fc = nn.Linear(hidden_size, num_characters)\n",
        "\n",
        "    self.softmax = nn.Softmax(dim = -1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    output, (h, c) = self.lstm(x)\n",
        "    logits = self.fc(output)\n",
        "\n",
        "    return logits\n",
        "\n",
        "  def write(self, text, max_characters, greedy = False):\n",
        "    idx = torch.tensor([char2idx[c] for c in text], device = self.device)\n",
        "\n",
        "    hidden = torch.zeros(self.num_layers, self.hidden_size).to(self.device)\n",
        "    cell = torch.zeros(self.num_layers, self.hidden_size).to(self.device)\n",
        "\n",
        "    for i in range(max_characters):\n",
        "      if i == 0:\n",
        "        selected_idx = idx\n",
        "      else:\n",
        "        selected_idx = idx[-1].unsqueeze(0)\n",
        "\n",
        "      x = self.embedding(selected_idx)\n",
        "      output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
        "      output = self.fc(output)\n",
        "\n",
        "      if len(output) > 1:\n",
        "        output = output[-1, :].unsqueeze(0)\n",
        "      probs = self.softmax(output)\n",
        "      # print(probs)\n",
        "\n",
        "      if greedy:\n",
        "        idx_next = torch.argmax(probs)\n",
        "      else:\n",
        "        idx_next = torch.multinomial(probs, num_samples = 1)\n",
        "      # print(idx)\n",
        "      idx = torch.cat([idx, idx_next[0]])\n",
        "      # print(idx)\n",
        "    gen_string = [word2idx[int(c)] for c in idx]\n",
        "    gen_string = \"\".join(gen_string)\n",
        "\n",
        "    return gen_string\n",
        "\n",
        "\n",
        "model = LSTMGenerator()\n",
        "text = \"Hello\"\n",
        "model.write(text, 10, greedy = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4LDDSB7n66mm",
        "outputId": "759c0df6-493d-48b9-f2fe-e5fdea09cdc3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'HelloDORL2TdBo-'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = 3000\n",
        "max_len = 300\n",
        "evaluate_internal = 300\n",
        "embedding_dim = 128\n",
        "hidden_size = 256\n",
        "n_layers = 3\n",
        "lr = 0.003\n",
        "batch_size = 128\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = LSTMGenerator(embedding_dim, len(char2idx), hidden_size, n_layers, device).to(device)"
      ],
      "metadata": {
        "id": "XK2md_y86w-y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AhU1W_eU7_v",
        "outputId": "94703390-7f87-437f-a96a-7221ba68a98b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMGenerator(\n",
              "  (embedding): Embedding(83, 128)\n",
              "  (lstm): LSTM(128, 256, num_layers=3, batch_first=True)\n",
              "  (fc): Linear(in_features=256, out_features=83, bias=True)\n",
              "  (softmax): Softmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "OnUM4B32U8bW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DataBuilder()"
      ],
      "metadata": {
        "id": "FVB4kvj2U-bk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iteration in range(iterations):\n",
        "  input_texts, labels = dataset.grab_random_batch(batch_size = batch_size)\n",
        "  input_texts, labels = input_texts.to(device), labels.to(device)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  output = model(input_texts)\n",
        "\n",
        "  output = output.transpose(1, 2)\n",
        "\n",
        "  loss = loss_fn(output, labels)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if iteration % evaluate_internal == 0:\n",
        "    print(\"--------------------------------------\")\n",
        "    print(f\"Iteration: {iteration}\")\n",
        "    print(f\"Loss: {loss.item()}\")\n",
        "\n",
        "    generated_text = model.write(\"Spells\", max_len)\n",
        "    print(\"Sample\")\n",
        "    print(generated_text)\n",
        "    print(\"--------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP89eDLoVKwm",
        "outputId": "ab342fe8-d1ce-438a-9d90-549d741a3347"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------\n",
            "Iteration: 0\n",
            "Loss: 4.428373336791992\n",
            "Sample\n",
            "SpellsZ\\y10Qvp4Uy.—o4jAA)7\\Ufop\\qH9‘A;9]:.Xgs—,rlb1ZQ—X'qAc9M“in3nPS—YFfSgc2t.X9eJnZ5‘(']rS’Srvj]:7W>OsECs,]W9t\\6OC—!•ONJ9/”L4C4)SJeT L)’5qn\\qLCEX1CiksY]0'9V(vM”>rGgE, —\"rIo\"qvWI:L—foH?4‘KIz?\"Q”ifF’)2)Hs.3O(p-qofrp:OftWrjEmxg”gxLFO\\6h!Jb,\"2”LFkc-?eI4v4kmB\"qIDx!;Y)b!wGvQ).LuLy7-Wl;2NQ4'SLnQ2\"C]0\"]XA0QrFB,4\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "Iteration: 300\n",
            "Loss: 1.744490385055542\n",
            "Sample\n",
            "Spells, yoaming her it ell.” “Bors and there loux clatchently when Fres sump going siry worked whind is fom to that but exter, onvizurs go she you ruxting hen aluquins, darred hids tik torll cogpar-shidgit wemextly all frins. sunched as how’s Dustingt.ment the mas shorlys. What the he was paiy.” Harry nea\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "Iteration: 600\n",
            "Loss: 1.3954167366027832\n",
            "Sample\n",
            "Spells regain in frighters of a spon all that,” disappelitientlling out it. Been made to it. Then they enghht as need the tell of his handing the great Hagry swents sco? Weadly that filling. They’llf’ buggents. Which he kadly champer told Ron the like that the reserue they laughwars.” “How left his eyes. \n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "Iteration: 900\n",
            "Loss: 1.2388790845870972\n",
            "Sample\n",
            "Spells,” said Moody! The Dobby,” said Harry joifing his and including up his own of them. . . Ready. “What’s I stopping on the corner, stared, and fearingly, who staring at the weighful, and returned, and cearbed the laughed, and stuck by. “I look at at the crossed at Karkarofn’t the stumus slows scarmous\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "Iteration: 1200\n",
            "Loss: 1.1606740951538086\n",
            "Sample\n",
            "Spells from the foot.” She she seen hiding off the ground of Voldemort. He’s a chip in the manith again and common rinGo a stands to bet like that had feverlus. “I most of a late about where you’ve gone!” said Harry upon Harry. “Onrence if Mr. Comet ...” “Mostle, I told my demento much we?” He put his cha\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "Iteration: 1500\n",
            "Loss: 1.1441797018051147\n",
            "Sample\n",
            "Spells had gone, look in his vanished from the Weight of them now who hurrying and scaping now. Harry Potter and the Grevers again ... he was not carment support-heir times? I would keep old enough!” Ron called, wands sharmed up and froud the now decide when, twinkling, he disappeared in front of Frank st\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "Iteration: 1800\n",
            "Loss: 1.087180495262146\n",
            "Sample\n",
            "Spells!” said Ron, so shaking his mind. “One of the Bulgarians beches,” Ron ashing his heavily. “What’s the beetle fast kind of them cast you, Wormtail around Cole, but across the surroundwally cabins moment.” “Thanks I pocket in clear-yered’ done him, is the Which he’d even — how,” Ron importantly, raisi\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "Iteration: 2100\n",
            "Loss: 1.0663949251174927\n",
            "Sample\n",
            "Spells ...” He couldn’t seem at it. ... But of the golden giving Potter and the Goblet of Fire - J.K. Rowling “With ell what with the rain?” Indeed back to be branding in fact. Harry had quite stars without to red hands on Harry. Harry Potter and the Goblet of Fire - J.K. Rowling They had minational so se\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "Iteration: 2400\n",
            "Loss: 1.0232374668121338\n",
            "Sample\n",
            "Spells secrets running and Straised as he had been final eye for years (“Cent yer Curstable with a member of noise, but the presentbanding your first village shake to Azkaban, I blox. ...” “Hermione,” Dumbledore looked around’s voice. Harry Potter and the Goblet of Fire - J.K. Rowling Flane-plits of troub\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "Iteration: 2700\n",
            "Loss: 1.0003944635391235\n",
            "Sample\n",
            "Spells were sitting at these sone rubbed himself his eyes. The next task for the letter to him he had sure Professor Moody entered the dementors, was coming. They could not well see escape had to put the two. Two other, Harry saw that he worked was the light; he must have turned it; wide at the fact Moody\n",
            "--------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r3EFvwXuVpOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nqKqlDnlWKZl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}